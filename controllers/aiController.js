import { GoogleGenerativeAI } from '@google/generative-ai';
import config from '../config/config.js';

// Kh·ªüi t·∫°o Gemini AI
const apiKey = config.gemini?.apiKey && config.gemini.apiKey.trim() 
   ? config.gemini.apiKey.trim() 
   : null;

const genAI = apiKey ? new GoogleGenerativeAI(apiKey) : null;

// Debug: Log API key status (ch·ªâ trong development)
if (process.env.NODE_ENV === 'development') {
   console.log('ü§ñ Gemini AI:', genAI ? '‚úÖ ƒê√£ kh·ªüi t·∫°o' : '‚ùå Ch∆∞a c·∫•u h√¨nh (GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c set)');
   if (genAI) {
      console.log('üìù Model s·∫Ω s·ª≠ d·ª•ng: gemini-2.0-flash-exp');
   }
}

// System prompt cho AI t∆∞ v·∫•n v·ªÅ xe di chuy·ªÉn
const SYSTEM_PROMPT = `B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n v·ªÅ d·ªãch v·ª• v·∫≠n chuy·ªÉn v√† giao h√†ng t·∫°i ƒê√† N·∫µng. 
Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
- T∆∞ v·∫•n kh√°ch h√†ng v·ªÅ c√°c lo·∫°i xe ph√π h·ª£p v·ªõi nhu c·∫ßu v·∫≠n chuy·ªÉn
- Gi·∫£i th√≠ch v·ªÅ d·ªãch v·ª• giao h√†ng, b·ªëc x·∫øp, b·∫£o hi·ªÉm h√†ng h√≥a
- H∆∞·ªõng d·∫´n c√°ch ƒë·∫∑t ƒë∆°n h√†ng
- Tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ gi√° c·∫£, th·ªùi gian giao h√†ng
- T∆∞ v·∫•n v·ªÅ c√°c lo·∫°i xe: Xe t·∫£i nh·ªè, Xe t·∫£i v·ª´a, Xe t·∫£i l·ªõn, Xe th√πng, Xe ben, Xe b√°n t·∫£i, Xe k√©o

H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán, chuy√™n nghi·ªáp v√† h·ªØu √≠ch. N·∫øu kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y ƒë·ªÅ ngh·ªã kh√°ch h√†ng li√™n h·ªá tr·ª±c ti·∫øp v·ªõi ch√∫ng t√¥i.`;

/**
 * Chat v·ªõi AI Gemini
 * POST /api/ai/chat
 */
export const chatWithAI = async (req, res) => {
   try {
      const { message, conversationHistory = [] } = req.body;

      if (!message || !message.trim()) {
         return res.status(400).json({ 
            success: false, 
            message: 'Vui l√≤ng nh·∫≠p c√¢u h·ªèi' 
         });
      }

      if (!genAI) {
         console.error('GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng th√™m GEMINI_API_KEY v√†o file .env');
         return res.status(500).json({ 
            success: false, 
            message: 'AI service ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng li√™n h·ªá admin.',
            hint: process.env.NODE_ENV === 'development' ? 'Th√™m GEMINI_API_KEY v√†o file .env v√† restart server' : undefined
         });
      }

      // L·∫•y model Gemini (s·ª≠ d·ª•ng gemini-2.0-flash-exp ho·∫∑c gemini-pro)
      const model = genAI.getGenerativeModel({ 
         model: 'gemini-2.0-flash-exp' // Ho·∫∑c 'gemini-pro' n·∫øu model tr√™n kh√¥ng ho·∫°t ƒë·ªông
      });

      // X√¢y d·ª±ng prompt v·ªõi system prompt v√† conversation history
      let fullPrompt = SYSTEM_PROMPT + '\n\n';
      
      // Th√™m conversation history n·∫øu c√≥
      if (Array.isArray(conversationHistory) && conversationHistory.length > 0) {
         conversationHistory.forEach(msg => {
            if (msg.role && msg.content) {
               const roleLabel = msg.role === 'user' ? 'Kh√°ch h√†ng' : 'Tr·ª£ l√Ω AI';
               fullPrompt += `${roleLabel}: ${msg.content}\n\n`;
            }
         });
      }

      // Th√™m message hi·ªán t·∫°i
      fullPrompt += `Kh√°ch h√†ng: ${message.trim()}\n\nTr·ª£ l√Ω AI:`;

      // Generate content
      const result = await model.generateContent(fullPrompt);
      const response = await result.response;
      const aiMessage = response.text();

      return res.json({
         success: true,
         data: {
            message: aiMessage,
            timestamp: new Date().toISOString()
         }
      });

   } catch (error) {
      console.error('L·ªói khi chat v·ªõi AI:', error);
      return res.status(500).json({ 
         success: false, 
         message: 'L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi. Vui l√≤ng th·ª≠ l·∫°i sau.',
         error: process.env.NODE_ENV === 'development' ? error.message : undefined
      });
   }
};
